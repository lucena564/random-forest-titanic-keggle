# ğŸ“Š AnÃ¡lise ExploratÃ³ria de Dados - Titanic
---
## ğŸ“‹ O que foi Analisado

### 1ï¸âƒ£ CompreensÃ£o do Conjunto de Dados
- âœ… Estrutura: 891 observaÃ§Ãµes, 12 atributos
- âœ… Tipos de dados: 5 numÃ©ricos, 5 categÃ³ricos
- âœ… EstatÃ­sticas descritivas completas
- âœ… DistribuiÃ§Ãµes (mÃ©dia, mediana, quartis, assimetria)
- âœ… IdentificaÃ§Ã£o de outliers
- âœ… Cardinalidade de atributos categÃ³ricos
- âœ… AnÃ¡lise de valores ausentes (missing values)

### 2ï¸âƒ£ ImportÃ¢ncia e Relacionamentos
- âœ… Matriz de correlaÃ§Ã£o entre atributos numÃ©ricos
- âœ… Teste qui-quadrado para atributos categÃ³ricos
- âœ… IdentificaÃ§Ã£o de preditores fortes
- âœ… AnÃ¡lise de multicolinearidade
- âœ… SugestÃµes de feature engineering

### 3ï¸âƒ£ VisualizaÃ§Ãµes Geradas
- âœ… Histogramas de distribuiÃ§Ãµes numÃ©ricas
- âœ… Box plots agrupados por sobrevivÃªncia
- âœ… GrÃ¡ficos de barras para categÃ³ricos
- âœ… Heatmap de correlaÃ§Ã£o
- âœ… AnÃ¡lise de valores ausentes
- âœ… DistribuiÃ§Ã£o da variÃ¡vel alvo

### 4ï¸âƒ£ ExploraÃ§Ã£o para Ãrvore de DecisÃ£o
- âœ… Ranking de preditores para splits
- âœ… IdentificaÃ§Ã£o de problemas (overfitting/underfitting)
- âœ… EstratÃ©gias para classes desbalanceadas
- âœ… RecomendaÃ§Ã£o de mÃ©tricas de avaliaÃ§Ã£o
- âœ… SugestÃ£o de hiperparÃ¢metros iniciais

---

## ğŸ“Š Principais Descobertas

### ğŸ¯ Preditores Mais Importantes

| Atributo | Tipo | SignificÃ¢ncia | ObservaÃ§Ã£o |
|----------|------|---------------|------------|
| **Sex** | CategÃ³rico | p < 0.001 | â­â­â­ Preditor mais forte |
| **Pclass** | NumÃ©rico | p < 0.001 | â­â­â­ CorrelaÃ§Ã£o: -0.34 |
| **Fare** | NumÃ©rico | r = 0.26 | â­â­ Positiva moderada |
| **Age** | NumÃ©rico | ApÃ³s imputaÃ§Ã£o | â­ Importante |
| **Embarked** | CategÃ³rico | p < 0.001 | â­ Significativo |

### âš ï¸ Problemas Identificados

**Valores Ausentes:**
- `Age`: 177 valores (19.9%)
- `Cabin`: 687 valores (77.1%)
- `Embarked`: 2 valores (0.2%)

**Qualidade dos Dados:**
- DistribuiÃ§Ã£o assimÃ©trica em `Fare` (skewness = 4.79)
- Outliers presentes em `Age` e `Fare`
- Alta cardinalidade em `Cabin` (147 valores Ãºnicos)
- `Name` e `Ticket` sÃ£o Ãºnicos (requerem extraÃ§Ã£o)

**Desbalanceamento de Classes:**
- NÃ£o sobreviveu: 549 (62%)
- Sobreviveu: 342 (38%)
- RazÃ£o: 1.62:1 (moderadamente desbalanceado)

---

## ğŸ’¡ RecomendaÃ§Ãµes para PrÃ©-processamento

### 1. ImputaÃ§Ã£o de Valores Ausentes

```python
# Age - Imputar por grupo (melhor performance)
df['Age'].fillna(
    df.groupby(['Pclass', 'Sex'])['Age'].transform('median'), 
    inplace=True
)

# Cabin - Criar flag binÃ¡ria
df['HasCabin'] = df['Cabin'].notna().astype(int)

# Embarked - Imputar pela moda
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
```

### 2. Feature Engineering Sugerida

```python
# Tamanho da famÃ­lia
df['FamilySize'] = df['SibSp'] + df['Parch'] + 1

# Viajando sozinho
df['IsAlone'] = (df['FamilySize'] == 1).astype(int)

# TÃ­tulo extraÃ­do do nome
df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
# Agrupar tÃ­tulos raros: Mr, Mrs, Miss, Master, Rare

# Deck da cabine (primeira letra)
df['Deck'] = df['Cabin'].str[0]

# Faixas etÃ¡rias
df['AgeGroup'] = pd.cut(df['Age'], 
                        bins=[0, 12, 18, 60, 100],
                        labels=['Child', 'Teen', 'Adult', 'Senior'])

# Tarifa por pessoa
df['FarePerPerson'] = df['Fare'] / df['FamilySize']
```

### 3. Tratamento de Outliers (Opcional)

```python
# Fare - Considerar log transform ou cap nos percentis
df['Fare_log'] = np.log1p(df['Fare'])

# Ou limitar outliers extremos
Q1 = df['Fare'].quantile(0.25)
Q3 = df['Fare'].quantile(0.75)
IQR = Q3 - Q1
df['Fare_capped'] = df['Fare'].clip(lower=Q1-1.5*IQR, upper=Q3+1.5*IQR)
```

---

## ğŸŒ³ RecomendaÃ§Ãµes para Modelagem

### HiperparÃ¢metros Iniciais (Ponto de Partida)

```python
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(
    max_depth=5,                    # Evitar overfitting (dataset pequeno)
    min_samples_split=20,           # ~2% dos dados
    min_samples_leaf=10,            # ~1% dos dados
    max_leaf_nodes=20,              # Limitar complexidade
    class_weight='balanced',        # Compensar desbalanceamento
    criterion='gini',               # Testar tambÃ©m 'entropy'
    random_state=42
)
```

### HiperparÃ¢metros para Experimentar

| ParÃ¢metro | Valores Sugeridos | Impacto |
|-----------|-------------------|---------|
| `max_depth` | [3, 5, 7, 10, None] | Controla overfitting |
| `min_samples_split` | [10, 20, 30, 50] | MÃ­nimo para dividir nÃ³ |
| `min_samples_leaf` | [5, 10, 15, 20] | MÃ­nimo em folha |
| `criterion` | ['gini', 'entropy'] | MÃ©todo de split |
| `max_features` | [None, 'sqrt', 'log2'] | Features por split |

### MÃ©tricas de AvaliaÃ§Ã£o Recomendadas

```python
from sklearn.metrics import (
    f1_score,           # â­ PRINCIPAL (classes desbalanceadas)
    roc_auc_score,      # â­ ROBUSTA
    confusion_matrix,   # â­ OBRIGATÃ“RIA
    classification_report,
    accuracy_score
)

# Cross-validation
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5, scoring='f1')
print(f"F1-Score mÃ©dio: {scores.mean():.3f} (+/- {scores.std():.3f})")
```

**âš ï¸ NÃƒO confiar apenas em AcurÃ¡cia!** (pode ser enganosa com desbalanceamento)

---

## ğŸ“ Arquivos Gerados

### VisualizaÃ§Ãµes
Todas as figuras foram salvas em: `../results/figures/`

1. `01_histogramas_numericos.png` - DistribuiÃ§Ãµes
2. `02_boxplots_por_target.png` - ComparaÃ§Ã£o por sobrevivÃªncia
3. `03_analise_Sex.png` - AnÃ¡lise categÃ³rica
4. `03_analise_Pclass.png` - AnÃ¡lise de classe
5. `03_analise_Embarked.png` - Porto de embarque
6. `04_heatmap_correlacao.png` - Matriz de correlaÃ§Ã£o
7. `05_distribuicao_target.png` - VariÃ¡vel alvo
8. `06_valores_ausentes.png` - Missing values

### Dados Exportados
- `../results/eda_results.pkl` - Resultados da anÃ¡lise em formato pickle

**ConteÃºdo do arquivo pickle:**
```python
import pickle

with open('../results/eda_results.pkl', 'rb') as f:
    eda = pickle.load(f)

# DisponÃ­vel:
eda['numeric_features']              # Lista de features numÃ©ricas
eda['categorical_features']          # Lista de features categÃ³ricas
eda['missing_summary']               # DataFrame com missing values
eda['correlation_matrix']            # Matriz de correlaÃ§Ã£o
eda['chi2_results']                  # Resultados dos testes qui-quadrado
eda['feature_importance_ranking']    # Ranking de importÃ¢ncia
eda['recommended_hyperparameters']   # HiperparÃ¢metros sugeridos
eda['recommended_metrics']           # MÃ©tricas recomendadas
```

---

## ğŸš€ PrÃ³ximos Passos

### Etapa 2: PrÃ©-processamento (`02_preprocessing.ipynb`)

**O que fazer:**
1. âœ… Carregar os dados originais
2. âœ… Implementar imputaÃ§Ã£o conforme recomendado
3. âœ… Criar features engineered sugeridas
4. âœ… Codificar variÃ¡veis categÃ³ricas (One-Hot ou Label Encoding)
5. âœ… Normalizar/padronizar se necessÃ¡rio
6. âœ… Dividir em treino/validaÃ§Ã£o/teste
7. âœ… Salvar dados processados

**Usar como base:**
- EstratÃ©gias de imputaÃ§Ã£o documentadas acima
- Features sugeridas na anÃ¡lise
- MÃ³dulo `src/data_loader.py`

### Etapa 3: Modelagem (`03_decision_tree_model.ipynb`)

**O que fazer:**
1. âœ… Carregar dados processados
2. âœ… Treinar DecisionTreeClassifier com hiperparÃ¢metros iniciais
3. âœ… Avaliar com F1-Score, AUC-ROC e Matriz de ConfusÃ£o
4. âœ… Fazer Grid Search ou Random Search
5. âœ… Comparar com Random Forest
6. âœ… Visualizar Ã¡rvore resultante
7. âœ… Analisar feature importance
8. âœ… ValidaÃ§Ã£o cruzada (5-fold)
9. âœ… Fazer prediÃ§Ãµes no conjunto de teste
10. âœ… Documentar resultados

**Usar como base:**
- HiperparÃ¢metros iniciais recomendados
- MÃ©tricas de avaliaÃ§Ã£o definidas
- Features selecionadas como importantes

---

## ğŸ“š MÃ³dulos Auxiliares Criados

### `src/data_loader.py`
FunÃ§Ãµes para carregar e manipular dados:
```python
from src.data_loader import TitanicDataLoader

loader = TitanicDataLoader()
train, test = loader.load_data()
features = loader.get_feature_types()
missing = loader.get_missing_summary()
```

### `src/visualization.py`
FunÃ§Ãµes para criar visualizaÃ§Ãµes:
```python
from src.visualization import TitanicVisualizer

viz = TitanicVisualizer()
viz.plot_correlation_heatmap(df, numeric_cols)
viz.plot_categorical_analysis(df, 'Sex')
```

---

## ğŸ” Como Reproduzir esta AnÃ¡lise

### 1. Baixar os dados
```bash
# Acesse: https://www.kaggle.com/c/titanic/data
# Baixe train.csv e test.csv
# Coloque em: data/raw/
```

### 2. Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

### 3. Executar o notebook
```bash
cd notebooks
jupyter notebook 01_exploratory_analysis.ipynb
```
---

## ğŸ“Š EstatÃ­sticas RÃ¡pidas

```
Dataset: 891 observaÃ§Ãµes Ã— 12 atributos

Target (Survived):
â”œâ”€ NÃ£o (0): 549 passageiros (61.6%)
â””â”€ Sim  (1): 342 passageiros (38.4%)

Missing Values:
â”œâ”€ Age:      177 (19.9%) âš ï¸
â”œâ”€ Cabin:    687 (77.1%) âš ï¸âš ï¸
â””â”€ Embarked:   2 ( 0.2%)

CorrelaÃ§Ãµes com Survived:
â”œâ”€ Pclass: -0.34 (negativa) â­â­
â”œâ”€ Fare:   +0.26 (positiva) â­â­
â””â”€ Age:    -0.08 (fraca)

Testes Qui-Quadrado:
â”œâ”€ Sex:      p < 0.001 â­â­â­
â”œâ”€ Pclass:   p < 0.001 â­â­â­
â””â”€ Embarked: p < 0.001 â­â­
```

---

## â“ Perguntas Frequentes

### P: Posso usar outras features alÃ©m das sugeridas?
**R:** Sim! As sugestÃµes sÃ£o um ponto de partida. Experimente criar outras combinaÃ§Ãµes.

### P: Preciso seguir exatamente os hiperparÃ¢metros recomendados?
**R:** NÃ£o. SÃ£o valores iniciais baseados na anÃ¡lise. Experimente outros valores!

### P: E se eu quiser testar outros algoritmos?
**R:** Ã“timo! A anÃ¡lise serve de base para qualquer modelo. Compare os resultados!

### P: Como cito esta anÃ¡lise na apresentaÃ§Ã£o?
**R:** Exemplo: *"A anÃ¡lise exploratÃ³ria identificou Sex e Pclass como os preditores mais significativos (p < 0.001), orientando nossa estratÃ©gia de feature selection..."*

---